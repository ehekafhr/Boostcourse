# 확률론

프리코스 강의인 것 같다.. 다시 돌아보자.

확률론 부분은 가볍게 요약하고, 뒤의 인공지능에서의 통계학 사용에 대해서 되짚어 보자.

## 확률분포

sample space $X$ 위의 값들에 대해 확률을 가지고 이와 출력 데이터 $y$ 를 포함한 데이터 $(\textbf{x}, y)$ 를 추출하는 확률분포를
$$ (\textbf{x},y)\sim P_{data} $$

이때, sample space에 따라 이산형과 연속형 확률변수로 구분한다.

이산확률변수인 경우,

$$ P(X \in A) = \sum_{\textbf{x} \in A} P(X=\textbf{x}) $$

이고, 연속확률변수인 경우

$$ P(X \in A) = \int_{A} P(X=\textbf{x}) d\textbf{x} $$

이때, $P(\textbf{x})$ 는 y에 대한 정보를 주지 않는다. 단순히, $\textbf{x}$ 가 나타날 확률에 대한 정보이다.

이를 $\textbf{x}$ 에 대한 marginal 분포라고 하는데, $y$ 의 영향력을 없애기 위해,

$$ P(\textbf{x}) = \int_{y}P(\textbf{x}, y)dy $$

를 통해 y에 대해 모두 더해 준다(이산확률의 경우 시그마로 바꿔주자)

## 조건부확률

조건부확률 

$$P(A|B) = \frac{P(A \cap B)}{P(B)}$$

$P(B)$ 를 곱해 주면

$$ P(A \cap B)=P(A|B){P(B)} $$

베이즈 정리는 이를 통해, 

사전확률 $P(B)$ , 가능도 $P(A|B)$ , Evidence $P(A)$ 를 가지고 사후확률 $P(B|A)$ 를 계산한다.

즉, A라는 정보가 추가되었을 때 $B$ 를 가지고, 추가된 $P(A|B)와 P(A)$ 를 통해 $P(B|A)$ 를 계산한다.

$$ P(B|A) = P(B)\frac{P(A|B)}{P(A)} $$

이러한 방식으로 True와 False를 추측할 때,

4가지 경우가 나오게 된다.

True Positive(TP), False Positive(FP-1종 오류), False Negative(FN-2종 오류), True Negative(TN)

우리가 계산한 것은 정밀도 precision으로,  $P(\theta|D) = \frac{TP}{TP+FP}$ 이다.

실제로 Positive일 때 Positive로 추측할 확률을 민감도(Recall)이라고 하고( $\frac{TP}{TN}$ )

특이도는 Negative일 때 Negative로 추측할 확률이다. ( $\frac{TN}{TN+FP}$ )

## 기대값

확률분포를 통해 여러 가지 통계적 함수를 계산 가능하다.

예를 들어, 확률분포 $P(\textbf{x})$ 에 대해 

$\textbf{x}$ 를 곱해 준 후 적분과 급수를 취해 주면 기댓값을 계산할 수 있다.

generating function을 이용하면 분산과 Skewness 등의 통계량도 계산 가능하다.

### 대수의 법칙

데이터를 확률분포로부터 반복적으로 독립추출하면, 그 산술평균은 데이터의 기댓값으로 수렴한다.(기댓값이 계산 가능해야 한다)

$$ \frac{\sum_{i=1}^{n}{x_i}}{n} \rightarrow E_{X \sim P}[X] $$

를 만족한다.

분산은? 좀 작다. 불편추정량이다.

이러한 대수의 법칙을 이용하여, 몬테 카를로 샘플링 방식을 사용할 수 있다.

그냥 원하는 범위 내에서 n개를 샘플링한 뒤, n으로 나누어 주고 범위 크기를 곱해주면 된다! 참 쉽다.

이를 통해, 일반적으로는 적분이 불가능한 함수 (예: 오류항) 등의 적분값을 근사 가능하다.

# 통계학

## 통계적 모델링

적절한 가정을 하고, 확률분포를 추정하는 과정을 의미한다.

데이터가 어떠한 확률 분포를 가짐을 알고 있다면, 모수적 방법론을 쓸 수 있다.

모수들을 가지는 확률 분포를 가정한 뒤, 데이터에 가장 알맞은 모수를 찾는 방법론이다.

예를 들어, 조금 찌그러진 주사위를 굴리는 경우에는 확률은 모르겠지만, 카테고리 분포를 가짐을 가정한 뒤 모수만 구할 수 있다.

이러한 방식으로는 "확실한" 모수를 알 수는 없고, 확률적으로 어느 정도 보장되는 분포만 추정할 수 있다.

비모수적 방법론은 이러한 통계적 가정이 없는 방법론이다. 모델의 구조, 모수의 개수 등이 정해지지 않은 경우인데, 기계학습의 방법론들은 대부분 이쪽에 속하게 된다.

통계를 이용한 기계학습에서는 보통 로그가능도를 이용한다.

가능도(likelihood) $L(\theta ; \textbf{x})$ 는 모수가 $\theta$ 인 분포에서 $\textbf{x}$ 가 나올 확률이다.

주의할 점은 모수에 대한 확률이 아니라, $\textbf{x}$ 에 대한 확률이라는 것이다. 모수가 $\theta$ 일 확률을 의미하지는 않는다.

최대가능도 추정은 이러한 가능도를 최대화하는 모수 $\theta$ 를 찾는 문제이다.

데이터가 독립적으로 추출되면 독립사건이므로 최대가능도가 전부 곱해진다.

곱연산의 경우 값이 너무 작아지거나 커질 수 있고, 계산 비용이 크게 나오므로 로그를 취해 곱셈을 덧셈으로 만들어 준다. 이것이 로그가능도를 사용하는 이유이다.

RMSE에서 제곱을 취한 값을 최적화하는 것처럼, 단조증가함수이기 때문에 가능도의 최적화와 로그가능도의 최적화는 같은 문제이다.

이 최적값을 찾기 위해서는 각각의 모수에 대해 편미분 값이 0이 되는 모수들을 찾아주면 된다.

## 딥러닝에서

기계학습의 손실함수들은 통계학에서 출발했다. 예를 들어, cross-entropy의 경우는 위에서 나온 로그가능도 최대화 문제가 된다.

mse의 경우에는, 모델 예측오차의 분산을 최소화하는 문제가 된다.

이러한 손실(Risk, error, loss)는 충분히 많은 데이터가 있다면 대수의 법칙에 의해서 true값과 충분히 비슷한 식을 구할 수 있다.

손실함수들은 보통 모델의 확률분포와, 데이터의 확률분포의 거리를 의미한다.

여기서, 확률분포의 거리함수로는  총변동 거리, 쿨백-라이블러 발산(KL Divergence), 바슈타인 거리가 있다.

### KL Divergence

$$ KL(P\Vert Q) = \sum_{\textbf{x}\in X}P(x)log(\frac{P(\textbf{x})}{Q(\textbf{x})}) $$

연속확률변수의 경우에는 적분으로 정의한다.

이를 분류 문제에 적용하면, 정답과 추정 분포의 교차 엔트로피에서, 정답의 엔트로피를 뺀 값이다. 만약 두 분포가 같다면, 0이라는 최솟값을 갖게 된다.

이는 최대가능도 추정법에서 나온 계산과 같다.

## 인과관계와 상관관계

조건부확률로 계산하는 것은 상관관계이지, 인과관계가 아니다.

즉, A가 증가할 때 B가 증가한다는 것을 알 수 있지만, A가 원인인지, B가 원인인지, 혹은 또다른 C가 원인인지는 알 수 없다는 것이다.

이러한 인과관계를 고려한 모델을 만들 수도 있다.

인과관계를 고려한 모형은 데이터의 분포가 다르더라도 robust한 성질을 띄지만, 조건부확률보다 높은 정확도를 보장하지는 않는다.

인과관계는 중첩요인의 효과를 제거해야 한다. 즉, A와 B의 인과관계를 추론하기 위해 다른 요소 C가 끼치는 영향을 제거해야 한다는 것이다.

C가 True, False 식으로 나타난다면 비교집단에서 C의 분포가 같게 해 주어야 한다는 뜻이다.
