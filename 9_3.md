
# 9-3 학습 정리

### 선형 회귀 모델 테스트

테스트 데이터는 트레이닝 데이터에 포함되지 않는 새로운 데이터로, 이러한 데이터를 예측하는 것을 목표로 함.

scaler는 "training data에 fit 된" 상태로 사용하고,

`model.eval()` 후

`with torch.no_grad():` 문 안에서 test를 하는 것이 좋다.

test에서는 loss, accuracy를 계산한다.

결과의 표준화를 해제하려면  `scaler.inverse_transform()`을 사용하면 된다.

### 이진 분류 모델

선형 회귀와 같은 방식이나, 목표 변수가 사전에 정의된 두 가지 변수라는 점이 다르다.

무엇이 특정 범주에 속하는지, 아닌지에 대한 판단으로, 질병의 유무 판단이나 스팸 분류 등에 사용된다.

#### 트레이닝 데이터

Pandas에서 Target과 나머지를 분류하기 위해서, `df[Target]`과 `df.drop(["Target"],axis=1)`을 사용하면 분류 가능하다.

Target이 0과 1이 아닌 비정형 데이터로 주어질 경우가 많기 때문에, mapping을 통해 0과 1로 바꾸어 주어야 한다. .map(dict)

그 뒤, `sklearn.model_selection`의 `train_test_split()`을 통해 트레인 데이터, 테스트 데이터를 분리한다.

인자로는 데이터, 목표변수, 테스트 사이즈, 랜덤 난수(42)가 있다.

데이터 표준화는 StandardScaler 등의 표준화 기법을 사용한다.

Scaler에는 Minmax, Robust 등의 다양한 표준화 방식이 있다. RobustScaler의 경우는 이상치가 다른 값에 미치는 영향이 없다.

이때, train data에는 `fit_transform()`을 사용하지만

test_data에는 `transform()`을 사용한다.

이미 학습을 train_data에 맞춰진 scaler로 진행했기 때문에, 다른 scaler를 test에 사용하게 되면 정확도가 떨어지기 때문이다.

#### Dataset & DataLoader

데이터의 전처리와 배치 처리를 쉽게 하기 위해서 사용되는 클래스들이다.

배치는 데이터를 처리하는 묶음 단위로, minibatch gradient descent 알고리즘에서 사용된다.

minibatch GD는 BGD와 SGD의 절충안으로, SGD가 노이즈가 너무 커서 불안정해지는 문제를 batch 단위로 학습시킴으로서 절충했다.

Dataset class에는 

초기화 `__init__`, 데이터 크기 반환 `__len__`, 데이터 반환 `__getitem__` 메서드를 구현해야 한다.

`DataLoader()`는 dataset, batch_size, shuffle 유무를 인자로 받아 객체를 생성한다.

#### 이진 분류 모델에서

이진 분류를 위해 $ z = Wx+b $ 값을 구하고, 이 값을 통해 결정 경계를 찾아야 한다.

$ Wx +b $ 의 범위가 넓으므로, Sigmoid 함수를 통해 0과 1 사이의 값으로 보내 준다.

$$ Sigmoid(z) = \frac{1}{1+e^{-z}} $$

이 시그모이드 값을 1로 분류될 "확률"이라고 해석할 수도 있다..는데 솔직히 0과 1 사이라는 이유로 확률로 해석해도 되는지는 의문이 든다.

일반적으로는, 0.5를 기준으로 넘으면 1, 그렇지 않으면 0으로 분류한다.

### 손실 함수

출력값은 y, 0과 1 사이의 연속값을 가진다.

이진 분류 모델에서는 Binary Cross Entropy를 통해 예측 변수와 목표 변수 간의 차이를 측정한다.

이를 수식으로 나타내면, 정답 레이블 $t_i$, sigmoid 함수의 결괏값 $y_i$에 대해

$$ E(w,b) = -\sum_{i=1}^{n}{[t_i log y_i + (1-t_i)log(1-y_i)]}$$

가능도는 주어진 데이터가, 특정 모수 값에서 관찰될 확률 $P(X=x|\theta)  = L(\theta; X=x)$을 의미한다.

"모수가 $\theta$가 될 확률"을 의미하는 것이 아니라, "모수가 $\theta$일 때 특정 값이 나올 확률"이다.

이러한 가능도를 최대화하는 모수를 찾는 것을 최대가능도 추정이라고 한다.

데이터가 여러 개인 경우에, 데이터가 독립적으로 추출되었음을 가정하면

$$ L(\theta ; X) = \prod_{i=1}^{n}P(x_i|\theta) $$

이를 최대화하는 모수를 찾는 것이 목표이다.

이때, 최대가능도 대신 로그를 취한 로그 최대가능도를 최대화하면, 곱셈이 덧셈으로 변해 계산을 쉽게 할 수 있다.

위의 최대가능도를 통해 Cross-Entropy를 유도해 보자.

확률변수 T에 대해, 출력값이 1일 확률을 y라 하면 0일 확률은 1-y

이를 합치면 가능도 $$ P(T=t|x) = y^t(1-y)^{1-t} $$

간단하게, t=0일 때는 $y^t=1$이고 t=1일 때는 $(1-y)^{1-t}=1$ 이 되어 한쪽 항만 남는다.

곱셈 연산을 덧셈으로 변환하기 위해 log를 취하고, 최소화 문제로 바꾸기 위해 -를 취해 주면

$$ E(W,b) = -\sum_{i=1}^{n}[t_i logy_i + (1-t_i)log(1-y_i)]$$

가 된다. `nn.BCELoss()`로 호출할 수 있다.

#### 추가: 그래서 어떻게 최적화하는데?

우리의 목표는 위의 식을 최소화하는 w를 찾는 것이다. 즉,

$$ argmin_{w}(-\sum_{i=1}^{n}[(t_i logy_i +(1-t_i)log(1-y_i)])$$

가 목표이다. 위 식에서 i를 하나 떼와서, y에 대해 편미분하면

$$  \frac{\partial E}{\partial y}-\frac{t}{y} +\frac{1-t}{1-y} $$


y를 z에 대해 편미분하면

$$ \frac{\partial y}{\partial z} = y(1-y) $$

이다.(미분한 결과가, y에 대한 식으로 정리되어 나타난다)

$z = w^Tx+b$ 이므로, 각각의 $w_i$에 대해 

$$ \frac{\partial z}{\partial w} = -x_j $$

chain rule에 의해

$$ \frac{\partial E}{\partial z} = \frac{\partial E}{\partial y}\frac{\partial y}{\partial z} = -t(1-y) + (1-t)y = y-t $$

$$ \frac{\partial E}{\partial w_i} = \frac{\partial E}{\partial z}\frac{\partial z}{\partial w_i} = -x_i(y-t) $$

가 된다.

모든 $w_i$에 대해 미분값을 찾고, learning rate를 곱해서 빼주게 되면 한 step의 Gradient Descent가 된다.
