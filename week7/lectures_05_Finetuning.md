# Fine tuning

일반적으로 AI를 학습시킬때, 대규모 데이터셋으로 미리 학습된 모델의 weight를 가져와서 일부 가중치만 태스크에 맞게 조정하는 Fine-tuning, 전이학습 기법을 많이 사용한다.

Fine tuning을 하게 되면, 단순히 우리가 가지고 있는 dataset으로 학습을 시작하는 것보다 일반화된 성능 향상을 기대할 수 있다.

사전 학습 모델은 엄청난 수의 텍스트, 이미지 등을 학습하여 데이터의 의미, 패턴 등을 파악한 상태이기 때문에 이러한 layer들을 유지하는 것이 좋다.

또한, 랜덤 가중치로 시작하는 것보다 의미를 이미 해석하는 가중치로 시작하는 것이므로 학습 속도가 빠르고, 

적은 데이터셋으로도 의미있는 결과를 뽑아낼 수 있고,

일부 Weight(일반적으로는, 마지막의 Classifier만 unfreeze한다) 만 학습시키므로 학습 시간 단축의 효과가 있다.

## GPT

Auto-Regressive하게 문장을 생성해 준다.



## BERT
